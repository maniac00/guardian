{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157a13d1-ab68-4301-b288-7a8ed9fe5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05967a9c-b7f6-4bc0-8311-da78f33e7bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282725ba-f78e-4cf5-af17-37b589ae17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (44.2 MB)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f015cf1a-fcf8-44d5-abda-2791e60985a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (1.30.0)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.33.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (4.10.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: streamlit\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.30.0\n",
      "    Uninstalling streamlit-1.30.0:\n",
      "      Successfully uninstalled streamlit-1.30.0\n",
      "Successfully installed streamlit-1.33.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install streamlit --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93ba351-7d1f-4d6c-91bd-5ab52a70cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsungwook/Dev/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: absl-py in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: optree in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.10.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc05d289-e853-4181-b3d3-02f1291ad5bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.models' has no attribute 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model = tf.keras.models.load_model('../Shoplifting-Detection/Shoplifting/weight_steals/GATE_FLOW_SLOW_FAST/weights_at_epoch_shoplifting_net_model.h5')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Shoplifting-Detection/Shoplifting/weight_steals/GATE_FLOW_SLOW_FAST/weights_at_epoch_shoplifting_net_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.models' has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "#model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "#model = tf.keras.models.load_model('../Shoplifting-Detection/Shoplifting/weight_steals/GATE_FLOW_SLOW_FAST/weights_at_epoch_shoplifting_net_model.h5')\n",
    "model = tf.keras.models.load_weights('../Shoplifting-Detection/Shoplifting/weight_steals/GATE_FLOW_SLOW_FAST/weights_at_epoch_shoplifting_net_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb0bd6e2-a677-45c4-969c-690e4080df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라 설정\n",
    "cap = cv2.VideoCapture(1)  # 라즈베리파이 카메라 일반적으로 0번 디바이스 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e895c4d2-682a-453a-a9c6-535624bb7855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x1920 2 persons\n",
      "Speed: 12.9ms pre-process, 71.9ms inference, 12.9ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 2 persons\n",
      "Speed: 2.5ms pre-process, 61.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.3ms pre-process, 55.7ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.4ms pre-process, 54.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.3ms pre-process, 52.6ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.2ms pre-process, 53.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.6ms pre-process, 52.3ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.5ms pre-process, 53.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.8ms pre-process, 54.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.9ms pre-process, 52.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.8ms pre-process, 53.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.2ms pre-process, 54.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.9ms pre-process, 54.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.7ms pre-process, 52.8ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons, 1 remote\n",
      "Speed: 1.9ms pre-process, 53.9ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 1.9ms pre-process, 56.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.0ms pre-process, 55.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.0ms pre-process, 52.6ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.0ms pre-process, 53.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.2ms pre-process, 55.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.2ms pre-process, 51.9ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 1.9ms pre-process, 55.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.0ms pre-process, 52.0ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.0ms pre-process, 78.2ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 1.9ms pre-process, 55.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.8ms pre-process, 55.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.0ms pre-process, 54.2ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 refrigerator\n",
      "Speed: 3.2ms pre-process, 55.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.2ms pre-process, 54.9ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.7ms pre-process, 54.0ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.1ms pre-process, 54.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.3ms pre-process, 54.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.2ms pre-process, 54.3ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 3.3ms pre-process, 55.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.1ms pre-process, 54.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 3.0ms pre-process, 55.9ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.0ms pre-process, 53.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.9ms pre-process, 55.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 2.0ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle\n",
      "Speed: 2.4ms pre-process, 56.2ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.0ms pre-process, 54.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.9ms pre-process, 54.0ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.3ms pre-process, 54.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle\n",
      "Speed: 2.6ms pre-process, 55.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle\n",
      "Speed: 2.1ms pre-process, 53.7ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle\n",
      "Speed: 2.6ms pre-process, 54.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle\n",
      "Speed: 2.1ms pre-process, 55.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle\n",
      "Speed: 2.3ms pre-process, 56.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 1.9ms pre-process, 55.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle, 1 chair\n",
      "Speed: 2.6ms pre-process, 53.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle\n",
      "Speed: 1.7ms pre-process, 55.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.2ms pre-process, 55.2ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.0ms pre-process, 55.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.9ms pre-process, 55.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.5ms pre-process, 55.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup\n",
      "Speed: 3.0ms pre-process, 55.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup\n",
      "Speed: 2.0ms pre-process, 53.7ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup\n",
      "Speed: 2.9ms pre-process, 58.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 bottle, 1 cup\n",
      "Speed: 2.1ms pre-process, 55.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 cup\n",
      "Speed: 1.9ms pre-process, 53.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle, 1 cup\n",
      "Speed: 1.7ms pre-process, 54.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup, 1 chair\n",
      "Speed: 2.9ms pre-process, 56.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 cup\n",
      "Speed: 2.0ms pre-process, 54.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 cup\n",
      "Speed: 2.1ms pre-process, 57.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 bottle, 1 cup\n",
      "Speed: 2.2ms pre-process, 54.5ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup\n",
      "Speed: 2.2ms pre-process, 58.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons\n",
      "Speed: 2.1ms pre-process, 54.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle\n",
      "Speed: 2.5ms pre-process, 55.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons\n",
      "Speed: 2.0ms pre-process, 56.7ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 7 persons, 1 bottle, 1 cup\n",
      "Speed: 2.1ms pre-process, 54.7ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.2ms pre-process, 56.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 handbag, 2 cups, 1 laptop\n",
      "Speed: 2.3ms pre-process, 55.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 1.6ms pre-process, 55.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.3ms pre-process, 55.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 2 laptops\n",
      "Speed: 2.0ms pre-process, 53.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 cup, 2 laptops\n",
      "Speed: 2.7ms pre-process, 56.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 2 laptops\n",
      "Speed: 1.8ms pre-process, 56.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.2ms pre-process, 56.2ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.2ms pre-process, 53.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 cups, 1 laptop\n",
      "Speed: 2.5ms pre-process, 57.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 cups, 1 laptop\n",
      "Speed: 2.4ms pre-process, 55.9ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 2.5ms pre-process, 56.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 cup, 2 laptops\n",
      "Speed: 2.0ms pre-process, 55.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 cup, 2 laptops\n",
      "Speed: 2.7ms pre-process, 53.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 1 cup, 2 laptops\n",
      "Speed: 1.9ms pre-process, 54.2ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 53.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.1ms pre-process, 54.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 56.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.0ms pre-process, 55.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.5ms pre-process, 56.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.0ms pre-process, 53.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 1.9ms pre-process, 56.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 1.9ms pre-process, 56.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.9ms pre-process, 60.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.3ms pre-process, 54.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 54.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.0ms pre-process, 53.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.6ms pre-process, 56.7ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.3ms pre-process, 53.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 54.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.2ms pre-process, 56.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 3.1ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 53.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.4ms pre-process, 57.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 1.9ms pre-process, 54.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 2 laptops\n",
      "Speed: 2.5ms pre-process, 54.9ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 cake, 1 laptop\n",
      "Speed: 2.8ms pre-process, 56.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 54.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.8ms pre-process, 53.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 56.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.5ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 57.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.1ms pre-process, 53.0ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.6ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 56.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.6ms pre-process, 55.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.0ms pre-process, 54.3ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 3.3ms pre-process, 54.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.5ms inference, 1.1ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 3.2ms pre-process, 55.9ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 56.5ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 55.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.0ms pre-process, 54.5ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.5ms pre-process, 52.7ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 56.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.0ms pre-process, 54.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.4ms pre-process, 55.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.1ms pre-process, 53.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.7ms pre-process, 54.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.6ms pre-process, 53.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 3.0ms pre-process, 57.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.1ms pre-process, 54.5ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.6ms pre-process, 55.2ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 2 laptops\n",
      "Speed: 1.8ms pre-process, 53.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 3.0ms pre-process, 56.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 1 laptop\n",
      "Speed: 2.1ms pre-process, 53.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.9ms pre-process, 56.0ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 2.3ms pre-process, 55.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 1 chair, 1 laptop\n",
      "Speed: 2.1ms pre-process, 57.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.8ms pre-process, 55.3ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 6 persons, 2 bottles, 2 cups, 1 laptop\n",
      "Speed: 2.4ms pre-process, 57.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 2.0ms pre-process, 53.4ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.6ms pre-process, 56.0ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 2.0ms pre-process, 55.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 2 laptops\n",
      "Speed: 2.0ms pre-process, 54.1ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 2 laptops\n",
      "Speed: 2.0ms pre-process, 54.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 2 laptops\n",
      "Speed: 2.2ms pre-process, 53.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 1.9ms pre-process, 55.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 2.6ms pre-process, 55.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 2 laptops\n",
      "Speed: 2.1ms pre-process, 55.3ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 2 bottles, 2 cups, 2 laptops\n",
      "Speed: 3.1ms pre-process, 55.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 1.9ms pre-process, 53.6ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 2 cups, 1 laptop\n",
      "Speed: 2.6ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 1.9ms pre-process, 54.0ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.8ms pre-process, 55.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 2.0ms pre-process, 56.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 2 cups, 1 laptop\n",
      "Speed: 3.1ms pre-process, 55.0ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 bottles, 1 cup, 1 laptop\n",
      "Speed: 1.6ms pre-process, 55.3ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 donut, 1 laptop\n",
      "Speed: 2.8ms pre-process, 56.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 1 cup, 1 laptop\n",
      "Speed: 1.5ms pre-process, 53.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 1.8ms pre-process, 55.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.2ms pre-process, 54.1ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle, 2 cups, 1 laptop\n",
      "Speed: 2.7ms pre-process, 56.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 2 cups, 1 laptop\n",
      "Speed: 2.0ms pre-process, 54.4ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons, 1 bottle, 1 laptop\n",
      "Speed: 3.0ms pre-process, 54.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons, 1 bottle\n",
      "Speed: 2.0ms pre-process, 52.8ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons, 1 bottle\n",
      "Speed: 2.8ms pre-process, 56.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.4ms pre-process, 54.7ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.2ms pre-process, 52.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.1ms pre-process, 54.7ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.9ms pre-process, 56.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.0ms pre-process, 54.3ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.8ms pre-process, 54.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.8ms pre-process, 56.5ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.3ms pre-process, 54.6ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.5ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.8ms pre-process, 56.4ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.0ms pre-process, 56.8ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.7ms pre-process, 56.7ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.0ms pre-process, 58.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.5ms pre-process, 55.8ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.4ms pre-process, 54.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.7ms pre-process, 56.1ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 1.9ms pre-process, 53.7ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.5ms pre-process, 56.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.0ms pre-process, 55.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.5ms pre-process, 57.6ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 1.8ms pre-process, 56.9ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.7ms pre-process, 55.9ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.9ms pre-process, 54.0ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 2.4ms pre-process, 56.4ms inference, 0.4ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 1.8ms pre-process, 53.9ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 4 persons\n",
      "Speed: 2.3ms pre-process, 55.9ms inference, 0.3ms NMS per image at shape (1, 3, 384, 640)\n",
      "image 1/1: 1080x1920 5 persons\n",
      "Speed: 1.9ms pre-process, 52.4ms inference, 0.7ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # OpenCV 이미지를 PIL 이미지로 변환\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # 모델에 이미지 입력\n",
    "    results = model(img)\n",
    "    \n",
    "    # 결과 출력\n",
    "    results.print()  # 결과 콘솔에 출력\n",
    "    cv2.imshow('YOLOv5 Detection', np.squeeze(results.render()))  # 결과 이미지 보여주기\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # q를 누르면 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07dc0765-4e36-4dd9-8852-d8f2e6422f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7dbbdf-d3fb-4343-80e0-921b64554ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.11-cp311-cp311-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: absl-py in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (24.3.25)\n",
      "Collecting jax (from mediapipe)\n",
      "  Downloading jax-0.4.26-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Downloading jaxlib-0.4.26-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Downloading sounddevice-0.4.6-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jax->mediapipe) (1.11.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: filelock in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from torch->mediapipe) (2024.2.0)\n",
      "Requirement already satisfied: pycparser in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from jinja2->torch->mediapipe) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from sympy->torch->mediapipe) (1.3.0)\n",
      "Downloading mediapipe-0.10.11-cp311-cp311-macosx_11_0_universal2.whl (50.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sounddevice-0.4.6-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.26-cp311-cp311-macosx_11_0_arm64.whl (66.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sounddevice, jaxlib, jax, mediapipe\n",
      "Successfully installed jax-0.4.26 jaxlib-0.4.26 mediapipe-0.10.11 sounddevice-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b8f4d8-a354-4849-af97-b3e039333183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[1159]: Class CaptureDelegate is implemented in both /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x302112620) and /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x31f0b4860). One of the two will be used. Which one is undefined.\n",
      "objc[1159]: Class CVWindow is implemented in both /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x302112670) and /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1751f8a68). One of the two will be used. Which one is undefined.\n",
      "objc[1159]: Class CVView is implemented in both /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x302112698) and /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1751f8a90). One of the two will be used. Which one is undefined.\n",
      "objc[1159]: Class CVSlider is implemented in both /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x3021126c0) and /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1751f8ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6389112-8c49-42b7-96bb-ba741fb3e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp.solutions.hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1, # 손의 갯수\n",
    "    min_detection_confidence = 0.5,  # 검출 최소 한계 0.0 ~ 1.0, 디폴트 0.5\n",
    "    min_tracking_confidence = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32bb147-d68f-49fd-8a47-1e4ce4292c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958c28f6-f351-448a-b0cb-4e7b7ef9a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, img = cap.read()   \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    res = hands.process(imgRGB)  #검출에 성공하면\n",
    "    if(res.multi_hand_landmarks):\n",
    "        a_hand = res.multi_hand_landmarks[0]         # 첫 번째 손만 사용.\n",
    "        # 검출된 손의 landmark와 연결선을 그려준다.\n",
    "        mp.solutions.drawing_utils.draw_landmarks(imgRGB, a_hand, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "\n",
    "    imgBGR = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17944139-52c5-4836-ac92-2061614385ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d35052f-2bc1-4557-8811-d5f7095ead3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsungwook/Dev/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mediapipe 0.10.11\n",
      "Uninstalling mediapipe-0.10.11:\n",
      "  Would remove:\n",
      "    /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe-0.10.11.dist-info/*\n",
      "    /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages/mediapipe/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "898f719b-f39a-432e-9d0d-a0b3d079decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mediapipe 0.10.11\n",
      "Uninstalling mediapipe-0.10.11:\n",
      "  Successfully uninstalled mediapipe-0.10.11\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall mediapipe -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ce12d62-8a78-42a2-87b4-ade43795cba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe-silicon\n",
      "  Downloading mediapipe_silicon-0.9.2.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: absl-py in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (24.3.25)\n",
      "Requirement already satisfied: matplotlib in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (3.8.0)\n",
      "Requirement already satisfied: numpy in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from mediapipe-silicon) (3.20.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe-silicon) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimsungwook/Dev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe-silicon) (1.16.0)\n",
      "Downloading mediapipe_silicon-0.9.2.1-cp311-cp311-macosx_12_0_arm64.whl (64.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mediapipe-silicon\n",
      "Successfully installed mediapipe-silicon-0.9.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe-silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972268d-e0b4-41ed-9dcf-99e86fd981e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo5test",
   "language": "python",
   "name": "yolo5test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
